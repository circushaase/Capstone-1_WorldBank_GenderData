{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing as pp\n",
    "%pylab inline\n",
    "\n",
    "cause = pd.read_csv('/home/lara/Documents/Repository/Capstone-1_WorldBank_GenderData/causes.csv')\n",
    "effect = pd.read_csv('/home/lara/Documents/Repository/Capstone-1_WorldBank_GenderData/effects.csv')\n",
    "\n",
    "\n",
    "# Supervised Learning Modules\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping through various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('SGDR', SGDRegressor()))\n",
    "models.append(('GaussianPR', GaussianProcessRegressor()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('DTree', DecisionTreeRegressor()))\n",
    "models.append(('GradientBR', GradientBoostingRegressor()))\n",
    "models.append(('SVR', SVR()))\n",
    "models.append(('RF', RandomForestRegressor(n_jobs = -1, n_estimators = 500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = cause.pop('bc')\n",
    "X = cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    # boxplot algorithm comparison\\n    fig = pyplot.figure()\\n    fig.suptitle(title)\\n    ax = fig.add_subplot(111)\\n    pyplot.boxplot(results)\\n    ax.set_xticklabels(names)\\n    pyplot.ylim(0,1)\\n    pyplot.show()\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a function to evaluate each model\n",
    "def run_models(x,y):\n",
    "    results = []\n",
    "    names = []\n",
    "\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle = True, random_state=11)\n",
    "        cv_results = model_selection.cross_val_score(model, x, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "'''\n",
    "    # boxplot algorithm comparison\n",
    "    fig = pyplot.figure()\n",
    "    fig.suptitle(title)\n",
    "    ax = fig.add_subplot(111)\n",
    "    pyplot.boxplot(results)\n",
    "    ax.set_xticklabels(names)\n",
    "    pyplot.ylim(0,1)\n",
    "    pyplot.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDR: -71155615444173776472866578451398656.000000 (100488112409887734351412239781593088.000000)\n",
      "GaussianPR: -2880.365325 (360.577292)\n",
      "KNN: -380.370038 (67.390897)\n",
      "DTree: -419.900412 (109.487188)\n",
      "GradientBR: -214.404800 (49.169755)\n",
      "SVR: -542.577257 (62.328021)\n",
      "RF: -221.542367 (51.034570)\n"
     ]
    }
   ],
   "source": [
    "run_models(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tuning the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.001  and Epsilon = 0.0001 has score = -543.261142024\n",
      "C= 0.001  and Epsilon = 0.001 has score = -543.258900696\n",
      "C= 0.001  and Epsilon = 0.1 has score = -543.167182494\n",
      "C= 0.001  and Epsilon = 1 has score = -543.123666591\n",
      "C= 0.001  and Epsilon = 10 has score = -535.061387644\n",
      "C= 0.1  and Epsilon = 0.0001 has score = -543.042260735\n",
      "C= 0.1  and Epsilon = 0.001 has score = -543.042846983\n",
      "C= 0.1  and Epsilon = 0.1 has score = -543.249956514\n",
      "C= 0.1  and Epsilon = 1 has score = -543.009580546\n",
      "C= 0.1  and Epsilon = 10 has score = -535.042783806\n",
      "C= 1  and Epsilon = 0.0001 has score = -542.633125612\n",
      "C= 1  and Epsilon = 0.001 has score = -542.632876452\n",
      "C= 1  and Epsilon = 0.1 has score = -542.577256648\n",
      "C= 1  and Epsilon = 1 has score = -541.769006908\n",
      "C= 1  and Epsilon = 10 has score = -533.539445992\n",
      "C= 10  and Epsilon = 0.0001 has score = -532.291140532\n",
      "C= 10  and Epsilon = 0.001 has score = -532.290232137\n",
      "C= 10  and Epsilon = 0.1 has score = -532.188390945\n",
      "C= 10  and Epsilon = 1 has score = -531.287471765\n",
      "C= 10  and Epsilon = 10 has score = -527.051461004\n",
      "C= 100  and Epsilon = 0.0001 has score = -516.805505796\n",
      "C= 100  and Epsilon = 0.001 has score = -516.805711511\n",
      "C= 100  and Epsilon = 0.1 has score = -516.828222824\n",
      "C= 100  and Epsilon = 1 has score = -517.041855323\n",
      "C= 100  and Epsilon = 10 has score = -519.887351689\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "Es = [0.0001, 0.001, 0.1, 1, 10]\n",
    "\n",
    "for i in Cs:\n",
    "    for e in Es:\n",
    "        results =[]\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle = True, random_state=11)\n",
    "        results = model_selection.cross_val_score(SVR(C=i, epsilon = e), X, Y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "        score = results.mean()\n",
    "        print \"C=\", i, \" and Epsilon =\", e, \"has score =\",score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning the Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: ls n_estimators = 10 max_depth= 1 has score = -392.628879161\n",
      "Loss Function: ls n_estimators = 10 max_depth= 1 has score = -392.628879161\n",
      "Loss Function: ls n_estimators = 10 max_depth= 1 has score = -392.628879161\n",
      "Loss Function: ls n_estimators = 10 max_depth= 1 has score = -392.628879161\n",
      "Loss Function: ls n_estimators = 10 max_depth= 1 has score = -392.628879161\n",
      "Loss Function: ls n_estimators = 10 max_depth= 1 has score = -392.628879161\n",
      "Loss Function: ls n_estimators = 10 max_depth= 1 has score = -392.628879161\n",
      "Loss Function: ls n_estimators = 10 max_depth= 1 has score = -392.628879161\n",
      "Loss Function: ls n_estimators = 10 max_depth= 1 has score = -390.980468023\n",
      "Loss Function: ls n_estimators = 10 max_depth= 3 has score = -332.126828264\n",
      "Loss Function: ls n_estimators = 10 max_depth= 3 has score = -332.126828264\n",
      "Loss Function: ls n_estimators = 10 max_depth= 3 has score = -332.815771566\n",
      "Loss Function: ls n_estimators = 10 max_depth= 3 has score = -332.733597786\n",
      "Loss Function: ls n_estimators = 10 max_depth= 3 has score = -332.731719183\n",
      "Loss Function: ls n_estimators = 10 max_depth= 3 has score = -333.625820171\n",
      "Loss Function: ls n_estimators = 10 max_depth= 3 has score = -336.02434306\n",
      "Loss Function: ls n_estimators = 10 max_depth= 3 has score = -357.309935338\n",
      "Loss Function: ls n_estimators = 10 max_depth= 3 has score = -369.148711649\n",
      "Loss Function: ls n_estimators = 10 max_depth= 5 has score = -300.856704859\n",
      "Loss Function: ls n_estimators = 10 max_depth= 5 has score = -301.092571975\n",
      "Loss Function: ls n_estimators = 10 max_depth= 5 has score = -303.658241907\n",
      "Loss Function: ls n_estimators = 10 max_depth= 5 has score = -304.630121937\n",
      "Loss Function: ls n_estimators = 10 max_depth= 5 has score = -307.104559663\n",
      "Loss Function: ls n_estimators = 10 max_depth= 5 has score = -307.57029449\n",
      "Loss Function: ls n_estimators = 10 max_depth= 5 has score = -312.370078201\n",
      "Loss Function: ls n_estimators = 10 max_depth= 5 has score = -351.230398529\n",
      "Loss Function: ls n_estimators = 10 max_depth= 5 has score = -369.104175268\n",
      "Loss Function: ls n_estimators = 10 max_depth= 10 has score = -284.667008123\n",
      "Loss Function: ls n_estimators = 10 max_depth= 10 has score = -283.735550013\n",
      "Loss Function: ls n_estimators = 10 max_depth= 10 has score = -275.225807192\n",
      "Loss Function: ls n_estimators = 10 max_depth= 10 has score = -276.915816745\n",
      "Loss Function: ls n_estimators = 10 max_depth= 10 has score = -277.001188363\n",
      "Loss Function: ls n_estimators = 10 max_depth= 10 has score = -291.666578628\n",
      "Loss Function: ls n_estimators = 10 max_depth= 10 has score = -307.254823688\n",
      "Loss Function: ls n_estimators = 10 max_depth= 10 has score = -351.294035366\n",
      "Loss Function: ls n_estimators = 10 max_depth= 10 has score = -369.104175268\n",
      "Loss Function: ls n_estimators = 10 max_depth= 20 has score = -320.052359984\n",
      "Loss Function: ls n_estimators = 10 max_depth= 20 has score = -277.905833272\n",
      "Loss Function: ls n_estimators = 10 max_depth= 20 has score = -275.771719241\n",
      "Loss Function: ls n_estimators = 10 max_depth= 20 has score = -269.879280611\n",
      "Loss Function: ls n_estimators = 10 max_depth= 20 has score = -273.477339951\n",
      "Loss Function: ls n_estimators = 10 max_depth= 20 has score = -290.263910309\n",
      "Loss Function: ls n_estimators = 10 max_depth= 20 has score = -307.254823688\n",
      "Loss Function: ls n_estimators = 10 max_depth= 20 has score = -351.294035366\n",
      "Loss Function: ls n_estimators = 10 max_depth= 20 has score = -369.104175268\n",
      "Loss Function: ls n_estimators = 10 max_depth= 50 has score = -322.57281812\n",
      "Loss Function: ls n_estimators = 10 max_depth= 50 has score = -277.92611787\n",
      "Loss Function: ls n_estimators = 10 max_depth= 50 has score = -275.134390545\n",
      "Loss Function: ls n_estimators = 10 max_depth= 50 has score = -270.38907269\n",
      "Loss Function: ls n_estimators = 10 max_depth= 50 has score = -273.255131689\n",
      "Loss Function: ls n_estimators = 10 max_depth= 50 has score = -290.263910309\n",
      "Loss Function: ls n_estimators = 10 max_depth= 50 has score = -307.254823688\n",
      "Loss Function: ls n_estimators = 10 max_depth= 50 has score = -351.294035366\n",
      "Loss Function: ls n_estimators = 10 max_depth= 50 has score = -369.104175268\n",
      "Loss Function: ls n_estimators = 10 max_depth= 100 has score = -319.652106395\n",
      "Loss Function: ls n_estimators = 10 max_depth= 100 has score = -277.50324154\n",
      "Loss Function: ls n_estimators = 10 max_depth= 100 has score = -275.603565426\n",
      "Loss Function: ls n_estimators = 10 max_depth= 100 has score = -269.287299633\n",
      "Loss Function: ls n_estimators = 10 max_depth= 100 has score = -273.537453761\n",
      "Loss Function: ls n_estimators = 10 max_depth= 100 has score = -290.263910309\n",
      "Loss Function: ls n_estimators = 10 max_depth= 100 has score = -307.254823688\n",
      "Loss Function: ls n_estimators = 10 max_depth= 100 has score = -351.294035366\n",
      "Loss Function: ls n_estimators = 10 max_depth= 100 has score = -369.104175268\n",
      "Loss Function: ls n_estimators = 100 max_depth= 1 has score = -304.676745867\n",
      "Loss Function: ls n_estimators = 100 max_depth= 1 has score = -304.676745867\n",
      "Loss Function: ls n_estimators = 100 max_depth= 1 has score = -304.676745867\n",
      "Loss Function: ls n_estimators = 100 max_depth= 1 has score = -304.676385244\n",
      "Loss Function: ls n_estimators = 100 max_depth= 1 has score = -304.730414601\n",
      "Loss Function: ls n_estimators = 100 max_depth= 1 has score = -304.615069654\n",
      "Loss Function: ls n_estimators = 100 max_depth= 1 has score = -306.533349958\n",
      "Loss Function: ls n_estimators = 100 max_depth= 1 has score = -307.004449899\n",
      "Loss Function: ls n_estimators = 100 max_depth= 1 has score = -324.907715431\n",
      "Loss Function: ls n_estimators = 100 max_depth= 3 has score = -214.797995805\n",
      "Loss Function: ls n_estimators = 100 max_depth= 3 has score = -214.729697552\n",
      "Loss Function: ls n_estimators = 100 max_depth= 3 has score = -210.223261095\n",
      "Loss Function: ls n_estimators = 100 max_depth= 3 has score = -212.325637384\n",
      "Loss Function: ls n_estimators = 100 max_depth= 3 has score = -216.193521444\n",
      "Loss Function: ls n_estimators = 100 max_depth= 3 has score = -221.202074529\n",
      "Loss Function: ls n_estimators = 100 max_depth= 3 has score = -239.222718377\n",
      "Loss Function: ls n_estimators = 100 max_depth= 3 has score = -263.015100753\n",
      "Loss Function: ls n_estimators = 100 max_depth= 3 has score = -291.088082675\n",
      "Loss Function: ls n_estimators = 100 max_depth= 5 has score = -200.639157281\n",
      "Loss Function: ls n_estimators = 100 max_depth= 5 has score = -201.320559554\n",
      "Loss Function: ls n_estimators = 100 max_depth= 5 has score = -201.991729544\n",
      "Loss Function: ls n_estimators = 100 max_depth= 5 has score = -200.086250307\n",
      "Loss Function: ls n_estimators = 100 max_depth= 5 has score = -203.884111884\n",
      "Loss Function: ls n_estimators = 100 max_depth= 5 has score = -211.048220491\n",
      "Loss Function: ls n_estimators = 100 max_depth= 5 has score = -223.377776985\n",
      "Loss Function: ls n_estimators = 100 max_depth= 5 has score = -252.521508612\n",
      "Loss Function: ls n_estimators = 100 max_depth= 5 has score = -289.628836658\n",
      "Loss Function: ls n_estimators = 100 max_depth= 10 has score = -251.932518864\n",
      "Loss Function: ls n_estimators = 100 max_depth= 10 has score = -238.048705428\n",
      "Loss Function: ls n_estimators = 100 max_depth= 10 has score = -226.286398721\n",
      "Loss Function: ls n_estimators = 100 max_depth= 10 has score = -221.433865086\n",
      "Loss Function: ls n_estimators = 100 max_depth= 10 has score = -211.295620634\n",
      "Loss Function: ls n_estimators = 100 max_depth= 10 has score = -209.14178841\n",
      "Loss Function: ls n_estimators = 100 max_depth= 10 has score = -217.379813944\n",
      "Loss Function: ls n_estimators = 100 max_depth= 10 has score = -249.33981658\n",
      "Loss Function: ls n_estimators = 100 max_depth= 10 has score = -289.628836658\n",
      "Loss Function: ls n_estimators = 100 max_depth= 20 has score = -387.713827021\n",
      "Loss Function: ls n_estimators = 100 max_depth= 20 has score = -249.466464894\n",
      "Loss Function: ls n_estimators = 100 max_depth= 20 has score = -234.776107376\n",
      "Loss Function: ls n_estimators = 100 max_depth= 20 has score = -222.799531384\n",
      "Loss Function: ls n_estimators = 100 max_depth= 20 has score = -212.291957588\n",
      "Loss Function: ls n_estimators = 100 max_depth= 20 has score = -207.485238491\n",
      "Loss Function: ls n_estimators = 100 max_depth= 20 has score = -214.65960549\n",
      "Loss Function: ls n_estimators = 100 max_depth= 20 has score = -249.33981658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: ls n_estimators = 100 max_depth= 20 has score = -289.628836658\n",
      "Loss Function: ls n_estimators = 100 max_depth= 50 has score = -386.002375018\n",
      "Loss Function: ls n_estimators = 100 max_depth= 50 has score = -250.39028811\n",
      "Loss Function: ls n_estimators = 100 max_depth= 50 has score = -234.912715746\n",
      "Loss Function: ls n_estimators = 100 max_depth= 50 has score = -223.167574234\n",
      "Loss Function: ls n_estimators = 100 max_depth= 50 has score = -214.860477711\n",
      "Loss Function: ls n_estimators = 100 max_depth= 50 has score = -205.884858397\n",
      "Loss Function: ls n_estimators = 100 max_depth= 50 has score = -214.65960549\n",
      "Loss Function: ls n_estimators = 100 max_depth= 50 has score = -249.33981658\n",
      "Loss Function: ls n_estimators = 100 max_depth= 50 has score = -289.628836658\n",
      "Loss Function: ls n_estimators = 100 max_depth= 100 has score = -389.663793189\n",
      "Loss Function: ls n_estimators = 100 max_depth= 100 has score = -250.524577093\n",
      "Loss Function: ls n_estimators = 100 max_depth= 100 has score = -234.779861119\n",
      "Loss Function: ls n_estimators = 100 max_depth= 100 has score = -223.168965237\n",
      "Loss Function: ls n_estimators = 100 max_depth= 100 has score = -215.974043265\n",
      "Loss Function: ls n_estimators = 100 max_depth= 100 has score = -205.905421936\n",
      "Loss Function: ls n_estimators = 100 max_depth= 100 has score = -214.65960549\n",
      "Loss Function: ls n_estimators = 100 max_depth= 100 has score = -249.33981658\n",
      "Loss Function: ls n_estimators = 100 max_depth= 100 has score = -289.628836658\n",
      "Loss Function: ls n_estimators = 500 max_depth= 1 has score = -269.804590791\n",
      "Loss Function: ls n_estimators = 500 max_depth= 1 has score = -268.985039559\n",
      "Loss Function: ls n_estimators = 500 max_depth= 1 has score = -268.458736938\n",
      "Loss Function: ls n_estimators = 500 max_depth= 1 has score = -268.384191676\n",
      "Loss Function: ls n_estimators = 500 max_depth= 1 has score = -269.131299429\n",
      "Loss Function: ls n_estimators = 500 max_depth= 1 has score = -269.581701896\n",
      "Loss Function: ls n_estimators = 500 max_depth= 1 has score = -276.606077783\n",
      "Loss Function: ls n_estimators = 500 max_depth= 1 has score = -280.261173573\n",
      "Loss Function: ls n_estimators = 500 max_depth= 1 has score = -299.716357449\n",
      "Loss Function: ls n_estimators = 500 max_depth= 3 has score = -192.208225707\n",
      "Loss Function: ls n_estimators = 500 max_depth= 3 has score = -189.952447957\n",
      "Loss Function: ls n_estimators = 500 max_depth= 3 has score = -188.716433445\n",
      "Loss Function: ls n_estimators = 500 max_depth= 3 has score = -193.357370932\n",
      "Loss Function: ls n_estimators = 500 max_depth= 3 has score = -197.633716406\n",
      "Loss Function: ls n_estimators = 500 max_depth= 3 has score = -210.326703135\n",
      "Loss Function: ls n_estimators = 500 max_depth= 3 has score = -226.268409207\n",
      "Loss Function: ls n_estimators = 500 max_depth= 3 has score = -235.49547928\n",
      "Loss Function: ls n_estimators = 500 max_depth= 3 has score = -275.596536091\n",
      "Loss Function: ls n_estimators = 500 max_depth= 5 has score = -188.082021853\n",
      "Loss Function: ls n_estimators = 500 max_depth= 5 has score = -186.168369889\n",
      "Loss Function: ls n_estimators = 500 max_depth= 5 has score = -186.836574419\n",
      "Loss Function: ls n_estimators = 500 max_depth= 5 has score = -186.382361073\n",
      "Loss Function: ls n_estimators = 500 max_depth= 5 has score = -191.717585094\n",
      "Loss Function: ls n_estimators = 500 max_depth= 5 has score = -202.709955813\n",
      "Loss Function: ls n_estimators = 500 max_depth= 5 has score = -211.773375673\n",
      "Loss Function: ls n_estimators = 500 max_depth= 5 has score = -230.042387225\n",
      "Loss Function: ls n_estimators = 500 max_depth= 5 has score = -275.976898011\n",
      "Loss Function: ls n_estimators = 500 max_depth= 10 has score = -249.283451393\n",
      "Loss Function: ls n_estimators = 500 max_depth= 10 has score = -239.386742798\n",
      "Loss Function: ls n_estimators = 500 max_depth= 10 has score = -224.905358732\n",
      "Loss Function: ls n_estimators = 500 max_depth= 10 has score = -217.85775357\n",
      "Loss Function: ls n_estimators = 500 max_depth= 10 has score = -209.235924755\n",
      "Loss Function: ls n_estimators = 500 max_depth= 10 has score = -205.243353125\n",
      "Loss Function: ls n_estimators = 500 max_depth= 10 has score = -206.926839268\n",
      "Loss Function: ls n_estimators = 500 max_depth= 10 has score = -226.920020909\n",
      "Loss Function: ls n_estimators = 500 max_depth= 10 has score = -275.976898011\n",
      "Loss Function: ls n_estimators = 500 max_depth= 20 has score = -385.518191076\n",
      "Loss Function: ls n_estimators = 500 max_depth= 20 has score = -250.551354558\n",
      "Loss Function: ls n_estimators = 500 max_depth= 20 has score = -235.396023348\n",
      "Loss Function: ls n_estimators = 500 max_depth= 20 has score = -223.279730022\n",
      "Loss Function: ls n_estimators = 500 max_depth= 20 has score = -213.808096857\n",
      "Loss Function: ls n_estimators = 500 max_depth= 20 has score = -206.339478306\n",
      "Loss Function: ls n_estimators = 500 max_depth= 20 has score = -205.034316561\n",
      "Loss Function: ls n_estimators = 500 max_depth= 20 has score = -226.920020909\n",
      "Loss Function: ls n_estimators = 500 max_depth= 20 has score = -275.976898011\n",
      "Loss Function: ls n_estimators = 500 max_depth= 50 has score = -387.496914517\n",
      "Loss Function: ls n_estimators = 500 max_depth= 50 has score = -250.078556183\n",
      "Loss Function: ls n_estimators = 500 max_depth= 50 has score = -235.006636802\n",
      "Loss Function: ls n_estimators = 500 max_depth= 50 has score = -221.413673039\n",
      "Loss Function: ls n_estimators = 500 max_depth= 50 has score = -216.392362237\n",
      "Loss Function: ls n_estimators = 500 max_depth= 50 has score = -205.372376049\n",
      "Loss Function: ls n_estimators = 500 max_depth= 50 has score = -205.244654978\n",
      "Loss Function: ls n_estimators = 500 max_depth= 50 has score = -226.920020909\n",
      "Loss Function: ls n_estimators = 500 max_depth= 50 has score = -275.976898011\n",
      "Loss Function: ls n_estimators = 500 max_depth= 100 has score = -387.337591566\n",
      "Loss Function: ls n_estimators = 500 max_depth= 100 has score = -249.753568978\n",
      "Loss Function: ls n_estimators = 500 max_depth= 100 has score = -235.431940891\n",
      "Loss Function: ls n_estimators = 500 max_depth= 100 has score = -223.341490825\n",
      "Loss Function: ls n_estimators = 500 max_depth= 100 has score = -213.736780926\n",
      "Loss Function: ls n_estimators = 500 max_depth= 100 has score = -205.376089932\n",
      "Loss Function: ls n_estimators = 500 max_depth= 100 has score = -205.244654978\n",
      "Loss Function: ls n_estimators = 500 max_depth= 100 has score = -226.920020909\n",
      "Loss Function: ls n_estimators = 500 max_depth= 100 has score = -275.976898011\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 1 has score = -255.160068589\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 1 has score = -254.065045086\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 1 has score = -253.015126979\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 1 has score = -252.230849012\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 1 has score = -252.906477834\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 1 has score = -254.214485618\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 1 has score = -259.149781458\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 1 has score = -268.123870532\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 1 has score = -292.732306604\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 3 has score = -192.462881881\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 3 has score = -184.751351055\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 3 has score = -183.912734065\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 3 has score = -187.193050104\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 3 has score = -193.530729182\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 3 has score = -207.160941968\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 3 has score = -224.667356081\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 3 has score = -226.99228706\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 3 has score = -274.712754074\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 5 has score = -187.861481933\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 5 has score = -185.675763087\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 5 has score = -185.925178074\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 5 has score = -185.829456972\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 5 has score = -191.508938738\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 5 has score = -202.004900766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: ls n_estimators = 1000 max_depth= 5 has score = -209.548098498\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 5 has score = -225.407948414\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 5 has score = -274.934705053\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 10 has score = -249.667293707\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 10 has score = -241.228477003\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 10 has score = -225.273371073\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 10 has score = -217.933371895\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 10 has score = -208.632502153\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 10 has score = -205.242669796\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 10 has score = -206.797200495\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 10 has score = -225.174953346\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 10 has score = -274.934705053\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 20 has score = -387.28493336\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 20 has score = -249.003231851\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 20 has score = -235.026501932\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 20 has score = -222.302002089\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 20 has score = -214.317720289\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 20 has score = -206.789010968\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 20 has score = -205.453588827\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 20 has score = -225.174953346\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 20 has score = -274.934705053\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 50 has score = -386.980306527\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 50 has score = -250.476788589\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 50 has score = -235.029330788\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 50 has score = -222.593870321\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 50 has score = -216.674194159\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 50 has score = -205.896171939\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 50 has score = -205.617331656\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 50 has score = -225.174953346\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 50 has score = -274.934705053\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 100 has score = -385.953561345\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 100 has score = -248.446842371\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 100 has score = -234.421898064\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 100 has score = -223.930284051\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 100 has score = -216.696951473\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 100 has score = -205.872933511\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 100 has score = -205.617331656\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 100 has score = -225.174953346\n",
      "Loss Function: ls n_estimators = 1000 max_depth= 100 has score = -274.934705053\n",
      "Loss Function: lad n_estimators = 10 max_depth= 1 has score = -383.087849331\n",
      "Loss Function: lad n_estimators = 10 max_depth= 1 has score = -383.087849331\n",
      "Loss Function: lad n_estimators = 10 max_depth= 1 has score = -383.087849331\n",
      "Loss Function: lad n_estimators = 10 max_depth= 1 has score = -383.087849331\n",
      "Loss Function: lad n_estimators = 10 max_depth= 1 has score = -383.087849331\n",
      "Loss Function: lad n_estimators = 10 max_depth= 1 has score = -383.087849331\n",
      "Loss Function: lad n_estimators = 10 max_depth= 1 has score = -383.087849331\n",
      "Loss Function: lad n_estimators = 10 max_depth= 1 has score = -383.087849331\n",
      "Loss Function: lad n_estimators = 10 max_depth= 1 has score = -381.830895977\n",
      "Loss Function: lad n_estimators = 10 max_depth= 3 has score = -333.296093269\n",
      "Loss Function: lad n_estimators = 10 max_depth= 3 has score = -332.879572243\n",
      "Loss Function: lad n_estimators = 10 max_depth= 3 has score = -332.892193154\n",
      "Loss Function: lad n_estimators = 10 max_depth= 3 has score = -333.382584776\n",
      "Loss Function: lad n_estimators = 10 max_depth= 3 has score = -335.463753707\n",
      "Loss Function: lad n_estimators = 10 max_depth= 3 has score = -338.68950881\n",
      "Loss Function: lad n_estimators = 10 max_depth= 3 has score = -340.975048286\n",
      "Loss Function: lad n_estimators = 10 max_depth= 3 has score = -362.691761456\n",
      "Loss Function: lad n_estimators = 10 max_depth= 3 has score = -367.963674822\n",
      "Loss Function: lad n_estimators = 10 max_depth= 5 has score = -303.288705052\n",
      "Loss Function: lad n_estimators = 10 max_depth= 5 has score = -300.766414306\n",
      "Loss Function: lad n_estimators = 10 max_depth= 5 has score = -303.939909465\n",
      "Loss Function: lad n_estimators = 10 max_depth= 5 has score = -301.311008377\n",
      "Loss Function: lad n_estimators = 10 max_depth= 5 has score = -303.98705241\n",
      "Loss Function: lad n_estimators = 10 max_depth= 5 has score = -309.450811596\n",
      "Loss Function: lad n_estimators = 10 max_depth= 5 has score = -316.681528744\n",
      "Loss Function: lad n_estimators = 10 max_depth= 5 has score = -361.457678397\n",
      "Loss Function: lad n_estimators = 10 max_depth= 5 has score = -367.83223543\n",
      "Loss Function: lad n_estimators = 10 max_depth= 10 has score = -263.780538117\n",
      "Loss Function: lad n_estimators = 10 max_depth= 10 has score = -263.693437558\n",
      "Loss Function: lad n_estimators = 10 max_depth= 10 has score = -262.818678101\n",
      "Loss Function: lad n_estimators = 10 max_depth= 10 has score = -268.127684777\n",
      "Loss Function: lad n_estimators = 10 max_depth= 10 has score = -279.986216871\n",
      "Loss Function: lad n_estimators = 10 max_depth= 10 has score = -291.764471285\n",
      "Loss Function: lad n_estimators = 10 max_depth= 10 has score = -301.470479642\n",
      "Loss Function: lad n_estimators = 10 max_depth= 10 has score = -358.439050644\n",
      "Loss Function: lad n_estimators = 10 max_depth= 10 has score = -367.83223543\n",
      "Loss Function: lad n_estimators = 10 max_depth= 20 has score = -262.025151513\n",
      "Loss Function: lad n_estimators = 10 max_depth= 20 has score = -255.709267319\n",
      "Loss Function: lad n_estimators = 10 max_depth= 20 has score = -264.744134603\n",
      "Loss Function: lad n_estimators = 10 max_depth= 20 has score = -262.652109251\n",
      "Loss Function: lad n_estimators = 10 max_depth= 20 has score = -270.127005209\n",
      "Loss Function: lad n_estimators = 10 max_depth= 20 has score = -290.071005623\n",
      "Loss Function: lad n_estimators = 10 max_depth= 20 has score = -300.894408496\n",
      "Loss Function: lad n_estimators = 10 max_depth= 20 has score = -360.073310877\n",
      "Loss Function: lad n_estimators = 10 max_depth= 20 has score = -367.83223543\n",
      "Loss Function: lad n_estimators = 10 max_depth= 50 has score = -270.697064037\n",
      "Loss Function: lad n_estimators = 10 max_depth= 50 has score = -256.806774792\n",
      "Loss Function: lad n_estimators = 10 max_depth= 50 has score = -266.700663187\n",
      "Loss Function: lad n_estimators = 10 max_depth= 50 has score = -264.812703259\n",
      "Loss Function: lad n_estimators = 10 max_depth= 50 has score = -270.933979895\n",
      "Loss Function: lad n_estimators = 10 max_depth= 50 has score = -288.2700766\n",
      "Loss Function: lad n_estimators = 10 max_depth= 50 has score = -307.7157552\n",
      "Loss Function: lad n_estimators = 10 max_depth= 50 has score = -359.274089081\n",
      "Loss Function: lad n_estimators = 10 max_depth= 50 has score = -367.83223543\n",
      "Loss Function: lad n_estimators = 10 max_depth= 100 has score = -259.196455489\n",
      "Loss Function: lad n_estimators = 10 max_depth= 100 has score = -256.53462133\n",
      "Loss Function: lad n_estimators = 10 max_depth= 100 has score = -260.962465865\n",
      "Loss Function: lad n_estimators = 10 max_depth= 100 has score = -274.945235754\n",
      "Loss Function: lad n_estimators = 10 max_depth= 100 has score = -276.16326652\n",
      "Loss Function: lad n_estimators = 10 max_depth= 100 has score = -292.790193623\n",
      "Loss Function: lad n_estimators = 10 max_depth= 100 has score = -305.738190043\n",
      "Loss Function: lad n_estimators = 10 max_depth= 100 has score = -359.578298074\n",
      "Loss Function: lad n_estimators = 10 max_depth= 100 has score = -367.83223543\n",
      "Loss Function: lad n_estimators = 100 max_depth= 1 has score = -324.502752441\n",
      "Loss Function: lad n_estimators = 100 max_depth= 1 has score = -324.709163763\n",
      "Loss Function: lad n_estimators = 100 max_depth= 1 has score = -324.518617335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: lad n_estimators = 100 max_depth= 1 has score = -324.676808433\n",
      "Loss Function: lad n_estimators = 100 max_depth= 1 has score = -324.783019683\n",
      "Loss Function: lad n_estimators = 100 max_depth= 1 has score = -324.462460547\n",
      "Loss Function: lad n_estimators = 100 max_depth= 1 has score = -327.580895981\n",
      "Loss Function: lad n_estimators = 100 max_depth= 1 has score = -328.694905728\n",
      "Loss Function: lad n_estimators = 100 max_depth= 1 has score = -353.995586755\n",
      "Loss Function: lad n_estimators = 100 max_depth= 3 has score = -256.876450334\n",
      "Loss Function: lad n_estimators = 100 max_depth= 3 has score = -250.973283056\n",
      "Loss Function: lad n_estimators = 100 max_depth= 3 has score = -251.267789085\n",
      "Loss Function: lad n_estimators = 100 max_depth= 3 has score = -246.541300245\n",
      "Loss Function: lad n_estimators = 100 max_depth= 3 has score = -254.384339594\n",
      "Loss Function: lad n_estimators = 100 max_depth= 3 has score = -253.702288626\n",
      "Loss Function: lad n_estimators = 100 max_depth= 3 has score = -256.640895004\n",
      "Loss Function: lad n_estimators = 100 max_depth= 3 has score = -280.30797184\n",
      "Loss Function: lad n_estimators = 100 max_depth= 3 has score = -315.051905123\n",
      "Loss Function: lad n_estimators = 100 max_depth= 5 has score = -226.586689229\n",
      "Loss Function: lad n_estimators = 100 max_depth= 5 has score = -220.338157161\n",
      "Loss Function: lad n_estimators = 100 max_depth= 5 has score = -220.641781676\n",
      "Loss Function: lad n_estimators = 100 max_depth= 5 has score = -219.229393617\n",
      "Loss Function: lad n_estimators = 100 max_depth= 5 has score = -216.651219506\n",
      "Loss Function: lad n_estimators = 100 max_depth= 5 has score = -231.464811433\n",
      "Loss Function: lad n_estimators = 100 max_depth= 5 has score = -243.142106698\n",
      "Loss Function: lad n_estimators = 100 max_depth= 5 has score = -278.12953608\n",
      "Loss Function: lad n_estimators = 100 max_depth= 5 has score = -309.392002586\n",
      "Loss Function: lad n_estimators = 100 max_depth= 10 has score = -204.311837724\n",
      "Loss Function: lad n_estimators = 100 max_depth= 10 has score = -196.052580759\n",
      "Loss Function: lad n_estimators = 100 max_depth= 10 has score = -188.857216356\n",
      "Loss Function: lad n_estimators = 100 max_depth= 10 has score = -202.391537487\n",
      "Loss Function: lad n_estimators = 100 max_depth= 10 has score = -195.302613131\n",
      "Loss Function: lad n_estimators = 100 max_depth= 10 has score = -218.065441199\n",
      "Loss Function: lad n_estimators = 100 max_depth= 10 has score = -240.274615145\n",
      "Loss Function: lad n_estimators = 100 max_depth= 10 has score = -273.570392124\n",
      "Loss Function: lad n_estimators = 100 max_depth= 10 has score = -310.100673876\n",
      "Loss Function: lad n_estimators = 100 max_depth= 20 has score = -198.771119875\n",
      "Loss Function: lad n_estimators = 100 max_depth= 20 has score = -189.914059247\n",
      "Loss Function: lad n_estimators = 100 max_depth= 20 has score = -201.951397495\n",
      "Loss Function: lad n_estimators = 100 max_depth= 20 has score = -197.970476055\n",
      "Loss Function: lad n_estimators = 100 max_depth= 20 has score = -196.581623335\n",
      "Loss Function: lad n_estimators = 100 max_depth= 20 has score = -218.154301726\n",
      "Loss Function: lad n_estimators = 100 max_depth= 20 has score = -244.993459681\n",
      "Loss Function: lad n_estimators = 100 max_depth= 20 has score = -272.160749268\n",
      "Loss Function: lad n_estimators = 100 max_depth= 20 has score = -309.793748762\n",
      "Loss Function: lad n_estimators = 100 max_depth= 50 has score = -203.044228023\n",
      "Loss Function: lad n_estimators = 100 max_depth= 50 has score = -192.37024934\n",
      "Loss Function: lad n_estimators = 100 max_depth= 50 has score = -197.170353325\n",
      "Loss Function: lad n_estimators = 100 max_depth= 50 has score = -198.966387545\n",
      "Loss Function: lad n_estimators = 100 max_depth= 50 has score = -199.363812514\n",
      "Loss Function: lad n_estimators = 100 max_depth= 50 has score = -214.508129394\n",
      "Loss Function: lad n_estimators = 100 max_depth= 50 has score = -242.474724738\n",
      "Loss Function: lad n_estimators = 100 max_depth= 50 has score = -275.853184276\n",
      "Loss Function: lad n_estimators = 100 max_depth= 50 has score = -310.454074331\n",
      "Loss Function: lad n_estimators = 100 max_depth= 100 has score = -204.945937444\n",
      "Loss Function: lad n_estimators = 100 max_depth= 100 has score = -195.396002276\n",
      "Loss Function: lad n_estimators = 100 max_depth= 100 has score = -198.010985968\n",
      "Loss Function: lad n_estimators = 100 max_depth= 100 has score = -196.221425129\n",
      "Loss Function: lad n_estimators = 100 max_depth= 100 has score = -199.126262931\n",
      "Loss Function: lad n_estimators = 100 max_depth= 100 has score = -216.037754104\n",
      "Loss Function: lad n_estimators = 100 max_depth= 100 has score = -249.804108568\n",
      "Loss Function: lad n_estimators = 100 max_depth= 100 has score = -274.906734424\n",
      "Loss Function: lad n_estimators = 100 max_depth= 100 has score = -311.349047086\n",
      "Loss Function: lad n_estimators = 500 max_depth= 1 has score = -298.900385902\n",
      "Loss Function: lad n_estimators = 500 max_depth= 1 has score = -298.3371352\n",
      "Loss Function: lad n_estimators = 500 max_depth= 1 has score = -298.9625815\n",
      "Loss Function: lad n_estimators = 500 max_depth= 1 has score = -302.401408698\n",
      "Loss Function: lad n_estimators = 500 max_depth= 1 has score = -303.112977102\n",
      "Loss Function: lad n_estimators = 500 max_depth= 1 has score = -299.833746802\n",
      "Loss Function: lad n_estimators = 500 max_depth= 1 has score = -307.619662063\n",
      "Loss Function: lad n_estimators = 500 max_depth= 1 has score = -312.831146753\n",
      "Loss Function: lad n_estimators = 500 max_depth= 1 has score = -336.360256153\n",
      "Loss Function: lad n_estimators = 500 max_depth= 3 has score = -227.782799988\n",
      "Loss Function: lad n_estimators = 500 max_depth= 3 has score = -235.363045574\n",
      "Loss Function: lad n_estimators = 500 max_depth= 3 has score = -226.083572096\n",
      "Loss Function: lad n_estimators = 500 max_depth= 3 has score = -224.336553546\n",
      "Loss Function: lad n_estimators = 500 max_depth= 3 has score = -220.361992898\n",
      "Loss Function: lad n_estimators = 500 max_depth= 3 has score = -229.510947632\n",
      "Loss Function: lad n_estimators = 500 max_depth= 3 has score = -247.850643294\n",
      "Loss Function: lad n_estimators = 500 max_depth= 3 has score = -264.163570936\n",
      "Loss Function: lad n_estimators = 500 max_depth= 3 has score = -295.8965605\n",
      "Loss Function: lad n_estimators = 500 max_depth= 5 has score = -203.689716855\n",
      "Loss Function: lad n_estimators = 500 max_depth= 5 has score = -207.250726371\n",
      "Loss Function: lad n_estimators = 500 max_depth= 5 has score = -199.108293794\n",
      "Loss Function: lad n_estimators = 500 max_depth= 5 has score = -202.902390466\n",
      "Loss Function: lad n_estimators = 500 max_depth= 5 has score = -202.478350503\n",
      "Loss Function: lad n_estimators = 500 max_depth= 5 has score = -216.654996506\n",
      "Loss Function: lad n_estimators = 500 max_depth= 5 has score = -237.718541027\n",
      "Loss Function: lad n_estimators = 500 max_depth= 5 has score = -264.36019547\n",
      "Loss Function: lad n_estimators = 500 max_depth= 5 has score = -293.500435108\n",
      "Loss Function: lad n_estimators = 500 max_depth= 10 has score = -203.559607562\n",
      "Loss Function: lad n_estimators = 500 max_depth= 10 has score = -187.600944269\n",
      "Loss Function: lad n_estimators = 500 max_depth= 10 has score = -182.78834526\n",
      "Loss Function: lad n_estimators = 500 max_depth= 10 has score = -190.743030006\n",
      "Loss Function: lad n_estimators = 500 max_depth= 10 has score = -196.063061722\n",
      "Loss Function: lad n_estimators = 500 max_depth= 10 has score = -213.81278226\n",
      "Loss Function: lad n_estimators = 500 max_depth= 10 has score = -238.725833198\n",
      "Loss Function: lad n_estimators = 500 max_depth= 10 has score = -262.847141191\n",
      "Loss Function: lad n_estimators = 500 max_depth= 10 has score = -293.874999688\n",
      "Loss Function: lad n_estimators = 500 max_depth= 20 has score = -202.178313229\n",
      "Loss Function: lad n_estimators = 500 max_depth= 20 has score = -198.416998775\n",
      "Loss Function: lad n_estimators = 500 max_depth= 20 has score = -195.667005075\n",
      "Loss Function: lad n_estimators = 500 max_depth= 20 has score = -194.614495255\n",
      "Loss Function: lad n_estimators = 500 max_depth= 20 has score = -193.703590001\n",
      "Loss Function: lad n_estimators = 500 max_depth= 20 has score = -211.966862406\n",
      "Loss Function: lad n_estimators = 500 max_depth= 20 has score = -234.32062156\n",
      "Loss Function: lad n_estimators = 500 max_depth= 20 has score = -265.595120024\n",
      "Loss Function: lad n_estimators = 500 max_depth= 20 has score = -293.129714473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: lad n_estimators = 500 max_depth= 50 has score = -199.925360065\n",
      "Loss Function: lad n_estimators = 500 max_depth= 50 has score = -199.126995416\n",
      "Loss Function: lad n_estimators = 500 max_depth= 50 has score = -188.030571534\n",
      "Loss Function: lad n_estimators = 500 max_depth= 50 has score = -198.050188456\n",
      "Loss Function: lad n_estimators = 500 max_depth= 50 has score = -191.947726773\n",
      "Loss Function: lad n_estimators = 500 max_depth= 50 has score = -209.884967744\n",
      "Loss Function: lad n_estimators = 500 max_depth= 50 has score = -239.156813333\n",
      "Loss Function: lad n_estimators = 500 max_depth= 50 has score = -261.554255293\n",
      "Loss Function: lad n_estimators = 500 max_depth= 50 has score = -292.889327384\n",
      "Loss Function: lad n_estimators = 500 max_depth= 100 has score = -196.616947141\n",
      "Loss Function: lad n_estimators = 500 max_depth= 100 has score = -190.174798349\n",
      "Loss Function: lad n_estimators = 500 max_depth= 100 has score = -191.084430106\n",
      "Loss Function: lad n_estimators = 500 max_depth= 100 has score = -192.398581874\n",
      "Loss Function: lad n_estimators = 500 max_depth= 100 has score = -195.287495293\n",
      "Loss Function: lad n_estimators = 500 max_depth= 100 has score = -215.855072099\n",
      "Loss Function: lad n_estimators = 500 max_depth= 100 has score = -239.352024243\n",
      "Loss Function: lad n_estimators = 500 max_depth= 100 has score = -264.343950235\n",
      "Loss Function: lad n_estimators = 500 max_depth= 100 has score = -293.803841188\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 1 has score = -296.605065332\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 1 has score = -295.390771317\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 1 has score = -292.274906061\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 1 has score = -295.232757159\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 1 has score = -294.755599775\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 1 has score = -293.424866994\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 1 has score = -302.626578962\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 1 has score = -308.833021406\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 1 has score = -328.007744895\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 3 has score = -223.146333864\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 3 has score = -223.792564689\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 3 has score = -217.425690612\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 3 has score = -217.726088644\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 3 has score = -220.334882809\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 3 has score = -222.111796319\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 3 has score = -241.139735816\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 3 has score = -259.317380246\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 3 has score = -292.497673205\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 5 has score = -200.873711728\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 5 has score = -199.941691242\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 5 has score = -193.676345736\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 5 has score = -199.107212939\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 5 has score = -200.063522466\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 5 has score = -209.690517987\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 5 has score = -227.639426924\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 5 has score = -257.08841229\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 5 has score = -288.471770344\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 10 has score = -198.614738448\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 10 has score = -194.551328639\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 10 has score = -187.883338523\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 10 has score = -191.822001406\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 10 has score = -194.295837358\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 10 has score = -207.11280278\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 10 has score = -239.504536613\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 10 has score = -260.38599672\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 10 has score = -289.94385508\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 20 has score = -193.692850523\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 20 has score = -196.63505165\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 20 has score = -185.492212142\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 20 has score = -193.813284838\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 20 has score = -197.901011437\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 20 has score = -214.999609036\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 20 has score = -234.589966184\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 20 has score = -262.670327032\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 20 has score = -289.217793916\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 50 has score = -200.676704335\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 50 has score = -192.459903215\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 50 has score = -189.852963249\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 50 has score = -198.245927321\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 50 has score = -192.894408895\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 50 has score = -205.964059077\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 50 has score = -239.112964526\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 50 has score = -263.555317807\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 50 has score = -289.331814153\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 100 has score = -196.003019455\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 100 has score = -189.032973253\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 100 has score = -189.162019538\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 100 has score = -184.699856572\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 100 has score = -198.05792293\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 100 has score = -213.445660672\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 100 has score = -238.239189255\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 100 has score = -264.671356532\n",
      "Loss Function: lad n_estimators = 1000 max_depth= 100 has score = -289.151788707\n",
      "Loss Function: huber n_estimators = 10 max_depth= 1 has score = -390.70164211\n",
      "Loss Function: huber n_estimators = 10 max_depth= 1 has score = -390.70164211\n",
      "Loss Function: huber n_estimators = 10 max_depth= 1 has score = -390.70164211\n",
      "Loss Function: huber n_estimators = 10 max_depth= 1 has score = -390.70164211\n",
      "Loss Function: huber n_estimators = 10 max_depth= 1 has score = -390.70164211\n",
      "Loss Function: huber n_estimators = 10 max_depth= 1 has score = -390.70164211\n",
      "Loss Function: huber n_estimators = 10 max_depth= 1 has score = -390.70164211\n",
      "Loss Function: huber n_estimators = 10 max_depth= 1 has score = -390.70164211\n",
      "Loss Function: huber n_estimators = 10 max_depth= 1 has score = -389.383659879\n",
      "Loss Function: huber n_estimators = 10 max_depth= 3 has score = -332.381347828\n",
      "Loss Function: huber n_estimators = 10 max_depth= 3 has score = -331.649150707\n",
      "Loss Function: huber n_estimators = 10 max_depth= 3 has score = -332.288454136\n",
      "Loss Function: huber n_estimators = 10 max_depth= 3 has score = -332.2135789\n",
      "Loss Function: huber n_estimators = 10 max_depth= 3 has score = -332.297843949\n",
      "Loss Function: huber n_estimators = 10 max_depth= 3 has score = -335.647831511\n",
      "Loss Function: huber n_estimators = 10 max_depth= 3 has score = -336.760110907\n",
      "Loss Function: huber n_estimators = 10 max_depth= 3 has score = -361.276880428\n",
      "Loss Function: huber n_estimators = 10 max_depth= 3 has score = -369.073900202\n",
      "Loss Function: huber n_estimators = 10 max_depth= 5 has score = -305.035767707\n",
      "Loss Function: huber n_estimators = 10 max_depth= 5 has score = -307.312030726\n",
      "Loss Function: huber n_estimators = 10 max_depth= 5 has score = -306.059538681\n",
      "Loss Function: huber n_estimators = 10 max_depth= 5 has score = -307.94668625\n",
      "Loss Function: huber n_estimators = 10 max_depth= 5 has score = -307.922195274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: huber n_estimators = 10 max_depth= 5 has score = -311.052043325\n",
      "Loss Function: huber n_estimators = 10 max_depth= 5 has score = -314.269627912\n",
      "Loss Function: huber n_estimators = 10 max_depth= 5 has score = -356.214749647\n",
      "Loss Function: huber n_estimators = 10 max_depth= 5 has score = -369.073900202\n",
      "Loss Function: huber n_estimators = 10 max_depth= 10 has score = -293.860888199\n",
      "Loss Function: huber n_estimators = 10 max_depth= 10 has score = -286.398537761\n",
      "Loss Function: huber n_estimators = 10 max_depth= 10 has score = -290.481579233\n",
      "Loss Function: huber n_estimators = 10 max_depth= 10 has score = -281.432153439\n",
      "Loss Function: huber n_estimators = 10 max_depth= 10 has score = -291.264437383\n",
      "Loss Function: huber n_estimators = 10 max_depth= 10 has score = -294.52144041\n",
      "Loss Function: huber n_estimators = 10 max_depth= 10 has score = -305.912828566\n",
      "Loss Function: huber n_estimators = 10 max_depth= 10 has score = -356.36892181\n",
      "Loss Function: huber n_estimators = 10 max_depth= 10 has score = -369.073900202\n",
      "Loss Function: huber n_estimators = 10 max_depth= 20 has score = -306.662564578\n",
      "Loss Function: huber n_estimators = 10 max_depth= 20 has score = -288.882249468\n",
      "Loss Function: huber n_estimators = 10 max_depth= 20 has score = -286.100547044\n",
      "Loss Function: huber n_estimators = 10 max_depth= 20 has score = -272.868160882\n",
      "Loss Function: huber n_estimators = 10 max_depth= 20 has score = -282.02263873\n",
      "Loss Function: huber n_estimators = 10 max_depth= 20 has score = -294.029609197\n",
      "Loss Function: huber n_estimators = 10 max_depth= 20 has score = -305.912828566\n",
      "Loss Function: huber n_estimators = 10 max_depth= 20 has score = -356.36892181\n",
      "Loss Function: huber n_estimators = 10 max_depth= 20 has score = -369.073900202\n",
      "Loss Function: huber n_estimators = 10 max_depth= 50 has score = -307.934992896\n",
      "Loss Function: huber n_estimators = 10 max_depth= 50 has score = -287.330737463\n",
      "Loss Function: huber n_estimators = 10 max_depth= 50 has score = -284.32328614\n",
      "Loss Function: huber n_estimators = 10 max_depth= 50 has score = -272.45030071\n",
      "Loss Function: huber n_estimators = 10 max_depth= 50 has score = -281.083554082\n",
      "Loss Function: huber n_estimators = 10 max_depth= 50 has score = -294.061387025\n",
      "Loss Function: huber n_estimators = 10 max_depth= 50 has score = -305.912828566\n",
      "Loss Function: huber n_estimators = 10 max_depth= 50 has score = -356.36892181\n",
      "Loss Function: huber n_estimators = 10 max_depth= 50 has score = -369.073900202\n",
      "Loss Function: huber n_estimators = 10 max_depth= 100 has score = -304.958303627\n",
      "Loss Function: huber n_estimators = 10 max_depth= 100 has score = -293.382777631\n",
      "Loss Function: huber n_estimators = 10 max_depth= 100 has score = -284.922852732\n",
      "Loss Function: huber n_estimators = 10 max_depth= 100 has score = -272.684254945\n",
      "Loss Function: huber n_estimators = 10 max_depth= 100 has score = -281.284824603\n",
      "Loss Function: huber n_estimators = 10 max_depth= 100 has score = -294.029609197\n",
      "Loss Function: huber n_estimators = 10 max_depth= 100 has score = -305.912828566\n",
      "Loss Function: huber n_estimators = 10 max_depth= 100 has score = -356.36892181\n",
      "Loss Function: huber n_estimators = 10 max_depth= 100 has score = -369.073900202\n",
      "Loss Function: huber n_estimators = 100 max_depth= 1 has score = -305.167235105\n",
      "Loss Function: huber n_estimators = 100 max_depth= 1 has score = -305.167235105\n",
      "Loss Function: huber n_estimators = 100 max_depth= 1 has score = -305.167235105\n",
      "Loss Function: huber n_estimators = 100 max_depth= 1 has score = -305.260148699\n",
      "Loss Function: huber n_estimators = 100 max_depth= 1 has score = -305.540967677\n",
      "Loss Function: huber n_estimators = 100 max_depth= 1 has score = -305.455830596\n",
      "Loss Function: huber n_estimators = 100 max_depth= 1 has score = -307.401623809\n",
      "Loss Function: huber n_estimators = 100 max_depth= 1 has score = -307.450528431\n",
      "Loss Function: huber n_estimators = 100 max_depth= 1 has score = -324.962828223\n",
      "Loss Function: huber n_estimators = 100 max_depth= 3 has score = -220.309670437\n",
      "Loss Function: huber n_estimators = 100 max_depth= 3 has score = -215.094478204\n",
      "Loss Function: huber n_estimators = 100 max_depth= 3 has score = -216.430149221\n",
      "Loss Function: huber n_estimators = 100 max_depth= 3 has score = -218.786197543\n",
      "Loss Function: huber n_estimators = 100 max_depth= 3 has score = -218.993457398\n",
      "Loss Function: huber n_estimators = 100 max_depth= 3 has score = -224.541868987\n",
      "Loss Function: huber n_estimators = 100 max_depth= 3 has score = -240.384381521\n",
      "Loss Function: huber n_estimators = 100 max_depth= 3 has score = -264.444666402\n",
      "Loss Function: huber n_estimators = 100 max_depth= 3 has score = -291.86606522\n",
      "Loss Function: huber n_estimators = 100 max_depth= 5 has score = -205.050840598\n",
      "Loss Function: huber n_estimators = 100 max_depth= 5 has score = -203.067241747\n",
      "Loss Function: huber n_estimators = 100 max_depth= 5 has score = -200.361034477\n",
      "Loss Function: huber n_estimators = 100 max_depth= 5 has score = -205.652176633\n",
      "Loss Function: huber n_estimators = 100 max_depth= 5 has score = -209.844875094\n",
      "Loss Function: huber n_estimators = 100 max_depth= 5 has score = -214.980659491\n",
      "Loss Function: huber n_estimators = 100 max_depth= 5 has score = -229.442554534\n",
      "Loss Function: huber n_estimators = 100 max_depth= 5 has score = -249.159738519\n",
      "Loss Function: huber n_estimators = 100 max_depth= 5 has score = -290.195389731\n",
      "Loss Function: huber n_estimators = 100 max_depth= 10 has score = -266.684061918\n",
      "Loss Function: huber n_estimators = 100 max_depth= 10 has score = -242.158902968\n",
      "Loss Function: huber n_estimators = 100 max_depth= 10 has score = -237.978197908\n",
      "Loss Function: huber n_estimators = 100 max_depth= 10 has score = -218.180574622\n",
      "Loss Function: huber n_estimators = 100 max_depth= 10 has score = -221.918935475\n",
      "Loss Function: huber n_estimators = 100 max_depth= 10 has score = -213.319169847\n",
      "Loss Function: huber n_estimators = 100 max_depth= 10 has score = -219.773772381\n",
      "Loss Function: huber n_estimators = 100 max_depth= 10 has score = -244.846588784\n",
      "Loss Function: huber n_estimators = 100 max_depth= 10 has score = -290.195389731\n",
      "Loss Function: huber n_estimators = 100 max_depth= 20 has score = -344.752633652\n",
      "Loss Function: huber n_estimators = 100 max_depth= 20 has score = -264.563675033\n",
      "Loss Function: huber n_estimators = 100 max_depth= 20 has score = -241.903173874\n",
      "Loss Function: huber n_estimators = 100 max_depth= 20 has score = -227.657499781\n",
      "Loss Function: huber n_estimators = 100 max_depth= 20 has score = -219.026393412\n",
      "Loss Function: huber n_estimators = 100 max_depth= 20 has score = -210.533266093\n",
      "Loss Function: huber n_estimators = 100 max_depth= 20 has score = -219.005489066\n",
      "Loss Function: huber n_estimators = 100 max_depth= 20 has score = -244.846588784\n",
      "Loss Function: huber n_estimators = 100 max_depth= 20 has score = -290.195389731\n",
      "Loss Function: huber n_estimators = 100 max_depth= 50 has score = -347.576510299\n",
      "Loss Function: huber n_estimators = 100 max_depth= 50 has score = -268.010517049\n",
      "Loss Function: huber n_estimators = 100 max_depth= 50 has score = -237.648543481\n",
      "Loss Function: huber n_estimators = 100 max_depth= 50 has score = -222.957724423\n",
      "Loss Function: huber n_estimators = 100 max_depth= 50 has score = -218.986136826\n",
      "Loss Function: huber n_estimators = 100 max_depth= 50 has score = -210.331871117\n",
      "Loss Function: huber n_estimators = 100 max_depth= 50 has score = -219.005489066\n",
      "Loss Function: huber n_estimators = 100 max_depth= 50 has score = -244.846588784\n",
      "Loss Function: huber n_estimators = 100 max_depth= 50 has score = -290.195389731\n",
      "Loss Function: huber n_estimators = 100 max_depth= 100 has score = -346.323311073\n",
      "Loss Function: huber n_estimators = 100 max_depth= 100 has score = -268.110707793\n",
      "Loss Function: huber n_estimators = 100 max_depth= 100 has score = -238.791529337\n",
      "Loss Function: huber n_estimators = 100 max_depth= 100 has score = -226.307334798\n",
      "Loss Function: huber n_estimators = 100 max_depth= 100 has score = -218.978433627\n",
      "Loss Function: huber n_estimators = 100 max_depth= 100 has score = -210.325270047\n",
      "Loss Function: huber n_estimators = 100 max_depth= 100 has score = -219.005489066\n",
      "Loss Function: huber n_estimators = 100 max_depth= 100 has score = -244.846588784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: huber n_estimators = 100 max_depth= 100 has score = -290.195389731\n",
      "Loss Function: huber n_estimators = 500 max_depth= 1 has score = -270.567568688\n",
      "Loss Function: huber n_estimators = 500 max_depth= 1 has score = -269.594394911\n",
      "Loss Function: huber n_estimators = 500 max_depth= 1 has score = -269.052113357\n",
      "Loss Function: huber n_estimators = 500 max_depth= 1 has score = -269.085608736\n",
      "Loss Function: huber n_estimators = 500 max_depth= 1 has score = -269.818834035\n",
      "Loss Function: huber n_estimators = 500 max_depth= 1 has score = -270.389655738\n",
      "Loss Function: huber n_estimators = 500 max_depth= 1 has score = -277.284196841\n",
      "Loss Function: huber n_estimators = 500 max_depth= 1 has score = -279.947536171\n",
      "Loss Function: huber n_estimators = 500 max_depth= 1 has score = -300.293430921\n",
      "Loss Function: huber n_estimators = 500 max_depth= 3 has score = -196.487154935\n",
      "Loss Function: huber n_estimators = 500 max_depth= 3 has score = -189.637593344\n",
      "Loss Function: huber n_estimators = 500 max_depth= 3 has score = -191.418892765\n",
      "Loss Function: huber n_estimators = 500 max_depth= 3 has score = -195.516932611\n",
      "Loss Function: huber n_estimators = 500 max_depth= 3 has score = -201.894815069\n",
      "Loss Function: huber n_estimators = 500 max_depth= 3 has score = -214.314175363\n",
      "Loss Function: huber n_estimators = 500 max_depth= 3 has score = -231.914390545\n",
      "Loss Function: huber n_estimators = 500 max_depth= 3 has score = -236.949987446\n",
      "Loss Function: huber n_estimators = 500 max_depth= 3 has score = -278.25799261\n",
      "Loss Function: huber n_estimators = 500 max_depth= 5 has score = -185.746171733\n",
      "Loss Function: huber n_estimators = 500 max_depth= 5 has score = -193.088258773\n",
      "Loss Function: huber n_estimators = 500 max_depth= 5 has score = -190.244391692\n",
      "Loss Function: huber n_estimators = 500 max_depth= 5 has score = -195.882169031\n",
      "Loss Function: huber n_estimators = 500 max_depth= 5 has score = -196.026055388\n",
      "Loss Function: huber n_estimators = 500 max_depth= 5 has score = -206.78559682\n",
      "Loss Function: huber n_estimators = 500 max_depth= 5 has score = -218.000590312\n",
      "Loss Function: huber n_estimators = 500 max_depth= 5 has score = -228.616332655\n",
      "Loss Function: huber n_estimators = 500 max_depth= 5 has score = -277.404129542\n",
      "Loss Function: huber n_estimators = 500 max_depth= 10 has score = -266.051950964\n",
      "Loss Function: huber n_estimators = 500 max_depth= 10 has score = -238.570641395\n",
      "Loss Function: huber n_estimators = 500 max_depth= 10 has score = -236.151118533\n",
      "Loss Function: huber n_estimators = 500 max_depth= 10 has score = -216.135800795\n",
      "Loss Function: huber n_estimators = 500 max_depth= 10 has score = -220.320379055\n",
      "Loss Function: huber n_estimators = 500 max_depth= 10 has score = -209.622578164\n",
      "Loss Function: huber n_estimators = 500 max_depth= 10 has score = -208.659792525\n",
      "Loss Function: huber n_estimators = 500 max_depth= 10 has score = -227.021913074\n",
      "Loss Function: huber n_estimators = 500 max_depth= 10 has score = -277.404129542\n",
      "Loss Function: huber n_estimators = 500 max_depth= 20 has score = -347.044998712\n",
      "Loss Function: huber n_estimators = 500 max_depth= 20 has score = -263.257138135\n",
      "Loss Function: huber n_estimators = 500 max_depth= 20 has score = -240.617862892\n",
      "Loss Function: huber n_estimators = 500 max_depth= 20 has score = -224.36651761\n",
      "Loss Function: huber n_estimators = 500 max_depth= 20 has score = -219.301391934\n",
      "Loss Function: huber n_estimators = 500 max_depth= 20 has score = -207.23786725\n",
      "Loss Function: huber n_estimators = 500 max_depth= 20 has score = -209.714809753\n",
      "Loss Function: huber n_estimators = 500 max_depth= 20 has score = -227.021913074\n",
      "Loss Function: huber n_estimators = 500 max_depth= 20 has score = -277.404129542\n",
      "Loss Function: huber n_estimators = 500 max_depth= 50 has score = -345.458792876\n",
      "Loss Function: huber n_estimators = 500 max_depth= 50 has score = -271.587179378\n",
      "Loss Function: huber n_estimators = 500 max_depth= 50 has score = -237.679421335\n",
      "Loss Function: huber n_estimators = 500 max_depth= 50 has score = -224.22599582\n",
      "Loss Function: huber n_estimators = 500 max_depth= 50 has score = -217.953859764\n",
      "Loss Function: huber n_estimators = 500 max_depth= 50 has score = -206.847586274\n",
      "Loss Function: huber n_estimators = 500 max_depth= 50 has score = -209.760538805\n",
      "Loss Function: huber n_estimators = 500 max_depth= 50 has score = -227.021913074\n",
      "Loss Function: huber n_estimators = 500 max_depth= 50 has score = -277.404129542\n",
      "Loss Function: huber n_estimators = 500 max_depth= 100 has score = -344.994842761\n",
      "Loss Function: huber n_estimators = 500 max_depth= 100 has score = -266.055333565\n",
      "Loss Function: huber n_estimators = 500 max_depth= 100 has score = -239.771237299\n",
      "Loss Function: huber n_estimators = 500 max_depth= 100 has score = -223.246818072\n",
      "Loss Function: huber n_estimators = 500 max_depth= 100 has score = -221.795957032\n",
      "Loss Function: huber n_estimators = 500 max_depth= 100 has score = -206.808564795\n",
      "Loss Function: huber n_estimators = 500 max_depth= 100 has score = -209.760538805\n",
      "Loss Function: huber n_estimators = 500 max_depth= 100 has score = -227.021913074\n",
      "Loss Function: huber n_estimators = 500 max_depth= 100 has score = -277.404129542\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 1 has score = -255.677756239\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 1 has score = -254.800244114\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 1 has score = -253.51821022\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 1 has score = -252.408217468\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 1 has score = -252.826723483\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 1 has score = -254.480578197\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 1 has score = -259.598892237\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 1 has score = -266.862818799\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 1 has score = -293.51555137\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 3 has score = -194.1682271\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 3 has score = -188.124050149\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 3 has score = -190.886841971\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 3 has score = -192.037773076\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 3 has score = -201.991127644\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 3 has score = -214.807846388\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 3 has score = -231.206216869\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 3 has score = -230.111998802\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 3 has score = -281.189536317\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 5 has score = -183.810377319\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 5 has score = -188.434390814\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 5 has score = -186.777892253\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 5 has score = -193.957574585\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 5 has score = -196.648407797\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 5 has score = -205.950722744\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 5 has score = -214.221778079\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 5 has score = -224.928263585\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 5 has score = -280.547479925\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 10 has score = -256.354818261\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 10 has score = -241.326102916\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 10 has score = -236.254691549\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 10 has score = -207.180462628\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 10 has score = -215.014237792\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 10 has score = -209.859244773\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 10 has score = -207.015530449\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 10 has score = -224.886453843\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 10 has score = -280.547479925\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 20 has score = -344.898457701\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 20 has score = -266.036838493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: huber n_estimators = 1000 max_depth= 20 has score = -236.326543175\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 20 has score = -221.761458458\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 20 has score = -215.937634889\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 20 has score = -207.133548075\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 20 has score = -208.496927644\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 20 has score = -224.886453843\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 20 has score = -280.547479925\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 50 has score = -346.989079276\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 50 has score = -266.611212823\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 50 has score = -239.441411257\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 50 has score = -223.299665445\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 50 has score = -217.982921018\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 50 has score = -206.792213666\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 50 has score = -208.670133305\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 50 has score = -224.886453843\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 50 has score = -280.547479925\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 100 has score = -348.873580157\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 100 has score = -265.724715348\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 100 has score = -235.483869466\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 100 has score = -223.28120716\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 100 has score = -218.519571087\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 100 has score = -206.763330544\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 100 has score = -208.604198475\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 100 has score = -224.886453843\n",
      "Loss Function: huber n_estimators = 1000 max_depth= 100 has score = -280.547479925\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 1 has score = -1244.75242276\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 1 has score = -1244.75242276\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 1 has score = -1244.75242276\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 1 has score = -1244.75242276\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 1 has score = -1244.75242276\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 1 has score = -1244.75242276\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 1 has score = -1244.75242276\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 1 has score = -1242.11013615\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 1 has score = -1213.74968865\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 3 has score = -1018.45361435\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 3 has score = -1011.94710875\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 3 has score = -1011.90465681\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 3 has score = -1007.77928776\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 3 has score = -1006.06117462\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 3 has score = -1016.18297585\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 3 has score = -1011.53208422\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 3 has score = -1035.11926981\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 3 has score = -1080.79565511\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 5 has score = -957.648296766\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 5 has score = -950.866446617\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 5 has score = -955.563007051\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 5 has score = -961.780807245\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 5 has score = -968.553440359\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 5 has score = -950.708038021\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 5 has score = -974.573101251\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 5 has score = -1013.15845435\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 5 has score = -1063.82817924\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 10 has score = -878.274627915\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 10 has score = -890.274601803\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 10 has score = -885.981591707\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 10 has score = -895.227731579\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 10 has score = -918.954792072\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 10 has score = -917.105004292\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 10 has score = -944.225385054\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 10 has score = -1000.90207499\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 10 has score = -1067.49004506\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 20 has score = -862.181313331\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 20 has score = -868.447286902\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 20 has score = -877.431840352\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 20 has score = -895.4889462\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 20 has score = -902.57568406\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 20 has score = -913.827120375\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 20 has score = -939.437583737\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 20 has score = -1006.64796159\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 20 has score = -1067.49004506\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 50 has score = -859.374197098\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 50 has score = -868.287533844\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 50 has score = -878.339966638\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 50 has score = -894.214678579\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 50 has score = -916.611486202\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 50 has score = -914.020181133\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 50 has score = -947.025223429\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 50 has score = -1005.54721228\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 50 has score = -1067.49004506\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 100 has score = -862.488801001\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 100 has score = -873.65256902\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 100 has score = -879.429503783\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 100 has score = -890.434142168\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 100 has score = -910.475215233\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 100 has score = -912.216239092\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 100 has score = -944.144730352\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 100 has score = -1003.62312189\n",
      "Loss Function: quantile n_estimators = 10 max_depth= 100 has score = -1063.82817924\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 1 has score = -838.561488545\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 1 has score = -825.196444637\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 1 has score = -824.984274489\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 1 has score = -824.984274489\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 1 has score = -824.984274489\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 1 has score = -824.984274489\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 1 has score = -824.984274489\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 1 has score = -828.431530013\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 1 has score = -896.285718487\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 3 has score = -708.818471179\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 3 has score = -703.658148817\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 3 has score = -677.762365535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Function: quantile n_estimators = 100 max_depth= 3 has score = -672.962366153\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 3 has score = -668.946032481\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 3 has score = -679.725147099\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 3 has score = -674.43224982\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 3 has score = -678.485904205\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 3 has score = -800.935789428\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 5 has score = -591.902133754\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 5 has score = -590.635229099\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 5 has score = -562.394814559\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 5 has score = -558.400723441\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 5 has score = -555.736754302\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 5 has score = -558.076251341\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 5 has score = -572.741341318\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 5 has score = -627.217407921\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 5 has score = -801.990965455\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 10 has score = -442.841702434\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 10 has score = -423.59927473\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 10 has score = -413.489450922\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 10 has score = -414.756604846\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 10 has score = -433.715936798\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 10 has score = -438.720803709\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 10 has score = -479.319503818\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 10 has score = -610.232680317\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 10 has score = -802.836625846\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 20 has score = -317.158846133\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 20 has score = -337.631131764\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 20 has score = -359.630584835\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 20 has score = -388.624420341\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 20 has score = -409.533259399\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 20 has score = -426.280805605\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 20 has score = -476.08383482\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 20 has score = -603.335058997\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 20 has score = -801.936391157\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 50 has score = -307.745603084\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 50 has score = -325.588724922\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 50 has score = -351.270765722\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 50 has score = -384.333877487\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 50 has score = -401.341903944\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 50 has score = -431.748081551\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 50 has score = -474.26081527\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 50 has score = -605.197918404\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 50 has score = -803.064347767\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 100 has score = -315.905319408\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 100 has score = -327.593397254\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 100 has score = -354.972110331\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 100 has score = -379.34360139\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 100 has score = -389.968600661\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 100 has score = -424.969306603\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 100 has score = -477.184724249\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 100 has score = -603.082212592\n",
      "Loss Function: quantile n_estimators = 100 max_depth= 100 has score = -801.578553805\n",
      "Loss Function: quantile n_estimators = 500 max_depth= 1 has score = -828.903905718\n",
      "Loss Function: quantile n_estimators = 500 max_depth= 1 has score = -816.070370387\n",
      "Loss Function: quantile n_estimators = 500 max_depth= 1 has score = -803.90350438\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b3429b7f8e93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                 \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Loss Function:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_estimators =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max_depth=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"has score =\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1028\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1029\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m             residual = loss.negative_gradient(y, y_pred, k=k,\n\u001b[0;32m--> 763\u001b[0;31m                                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0;31m# induce regression tree on residuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mnegative_gradient\u001b[0;34m(self, y, pred, **kargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_opt= ['ls', 'lad', 'huber', 'quantile']\n",
    "estimators = [10, 100, 500, 1000]\n",
    "depth = [1,3,5,10,20,50,100]\n",
    "leaves = [1, 2, 3, 4, 5, 10, 20, 50, 100]\n",
    "\n",
    "for l in loss_opt:\n",
    "    for e in estimators:\n",
    "        for d in depth:\n",
    "            for leaf in leaves:\n",
    "                results =[]\n",
    "                kfold = model_selection.KFold(n_splits=10, shuffle = True, random_state=11)\n",
    "                results = model_selection.cross_val_score(GradientBoostingRegressor(loss=l, n_estimators = e, max_depth = d, min_samples_leaf = leaf), X, Y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "                score = results.mean()\n",
    "                print \"Loss Function:\", l, \"n_estimators =\", e, \"max_depth=\", d, \"min leaf samples=\", leaf, \"has score =\",score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 1e-100 has score = -2880.36532539\n",
      "Alpha = 1e-50 has score = -2880.36532539\n",
      "Alpha = 1e-20 has score = -2880.36532539\n",
      "Alpha = 1e-10 has score = -2880.36532539\n",
      "Alpha = 1e-05 has score = -2880.36539287\n",
      "Alpha = 1 has score = -2883.96792488\n",
      "Alpha = 10 has score = -2887.25987022\n",
      "Alpha = 100 has score = -2887.94906485\n"
     ]
    }
   ],
   "source": [
    "alphas= [1e-100,1e-50, 1e-20, 1e-10, 1e-5, 1, 10, 100 ]\n",
    "\n",
    "for a in alphas:\n",
    "    results =[]\n",
    "    kfold = model_selection.KFold(n_splits=10, shuffle = True, random_state=11)\n",
    "    results = model_selection.cross_val_score(GaussianProcessRegressor(alpha = a), X, Y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "    score = results.mean()\n",
    "    print \"Alpha =\",a , \"has score =\",score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 10 max_depth= 1 min leaf samples= 1 has score = -374.132925709\n",
      "n_estimators = 10 max_depth= 1 min leaf samples= 2 has score = -374.168343604\n",
      "n_estimators = 10 max_depth= 1 min leaf samples= 3 has score = -369.418467256\n",
      "n_estimators = 10 max_depth= 1 min leaf samples= 4 has score = -380.305123745\n",
      "n_estimators = 10 max_depth= 1 min leaf samples= 5 has score = -370.857172529\n",
      "n_estimators = 10 max_depth= 1 min leaf samples= 10 has score = -374.402727122\n",
      "n_estimators = 10 max_depth= 1 min leaf samples= 20 has score = -375.751760947\n",
      "n_estimators = 10 max_depth= 1 min leaf samples= 50 has score = -367.484983291\n",
      "n_estimators = 10 max_depth= 1 min leaf samples= 100 has score = -372.904719621\n",
      "n_estimators = 10 max_depth= 3 min leaf samples= 1 has score = -300.030601786\n",
      "n_estimators = 10 max_depth= 3 min leaf samples= 2 has score = -314.078554527\n",
      "n_estimators = 10 max_depth= 3 min leaf samples= 3 has score = -304.924495315\n",
      "n_estimators = 10 max_depth= 3 min leaf samples= 4 has score = -301.035395949\n",
      "n_estimators = 10 max_depth= 3 min leaf samples= 5 has score = -304.070790732\n",
      "n_estimators = 10 max_depth= 3 min leaf samples= 10 has score = -311.299190907\n",
      "n_estimators = 10 max_depth= 3 min leaf samples= 20 has score = -317.684153996\n",
      "n_estimators = 10 max_depth= 3 min leaf samples= 50 has score = -343.925142138\n",
      "n_estimators = 10 max_depth= 3 min leaf samples= 100 has score = -362.652690028\n",
      "n_estimators = 10 max_depth= 5 min leaf samples= 1 has score = -272.65692776\n",
      "n_estimators = 10 max_depth= 5 min leaf samples= 2 has score = -279.777769923\n",
      "n_estimators = 10 max_depth= 5 min leaf samples= 3 has score = -280.987384671\n",
      "n_estimators = 10 max_depth= 5 min leaf samples= 4 has score = -281.952774925\n",
      "n_estimators = 10 max_depth= 5 min leaf samples= 5 has score = -282.582844905\n",
      "n_estimators = 10 max_depth= 5 min leaf samples= 10 has score = -290.726009387\n",
      "n_estimators = 10 max_depth= 5 min leaf samples= 20 has score = -305.601423336\n",
      "n_estimators = 10 max_depth= 5 min leaf samples= 50 has score = -347.839877741\n",
      "n_estimators = 10 max_depth= 5 min leaf samples= 100 has score = -361.523130879\n",
      "n_estimators = 10 max_depth= 10 min leaf samples= 1 has score = -249.721655756\n",
      "n_estimators = 10 max_depth= 10 min leaf samples= 2 has score = -255.98903592\n",
      "n_estimators = 10 max_depth= 10 min leaf samples= 3 has score = -249.018298044\n",
      "n_estimators = 10 max_depth= 10 min leaf samples= 4 has score = -263.621013086\n",
      "n_estimators = 10 max_depth= 10 min leaf samples= 5 has score = -250.461217625\n",
      "n_estimators = 10 max_depth= 10 min leaf samples= 10 has score = -283.207267443\n",
      "n_estimators = 10 max_depth= 10 min leaf samples= 20 has score = -317.129808479\n",
      "n_estimators = 10 max_depth= 10 min leaf samples= 50 has score = -340.469425943\n",
      "n_estimators = 10 max_depth= 10 min leaf samples= 100 has score = -360.243542259\n",
      "n_estimators = 10 max_depth= 20 min leaf samples= 1 has score = -246.353983954\n",
      "n_estimators = 10 max_depth= 20 min leaf samples= 2 has score = -236.364150568\n",
      "n_estimators = 10 max_depth= 20 min leaf samples= 3 has score = -248.639035779\n",
      "n_estimators = 10 max_depth= 20 min leaf samples= 4 has score = -258.822899395\n",
      "n_estimators = 10 max_depth= 20 min leaf samples= 5 has score = -257.743840372\n",
      "n_estimators = 10 max_depth= 20 min leaf samples= 10 has score = -278.157138238\n",
      "n_estimators = 10 max_depth= 20 min leaf samples= 20 has score = -321.228278996\n",
      "n_estimators = 10 max_depth= 20 min leaf samples= 50 has score = -345.067900989\n",
      "n_estimators = 10 max_depth= 20 min leaf samples= 100 has score = -363.90073125\n",
      "n_estimators = 10 max_depth= 50 min leaf samples= 1 has score = -246.888367412\n",
      "n_estimators = 10 max_depth= 50 min leaf samples= 2 has score = -246.847684054\n",
      "n_estimators = 10 max_depth= 50 min leaf samples= 3 has score = -243.602344504\n",
      "n_estimators = 10 max_depth= 50 min leaf samples= 4 has score = -248.952719485\n",
      "n_estimators = 10 max_depth= 50 min leaf samples= 5 has score = -261.942717637\n",
      "n_estimators = 10 max_depth= 50 min leaf samples= 10 has score = -273.710670102\n",
      "n_estimators = 10 max_depth= 50 min leaf samples= 20 has score = -307.406746315\n",
      "n_estimators = 10 max_depth= 50 min leaf samples= 50 has score = -349.383708582\n",
      "n_estimators = 10 max_depth= 50 min leaf samples= 100 has score = -366.766736966\n",
      "n_estimators = 10 max_depth= 100 min leaf samples= 1 has score = -239.498351632\n",
      "n_estimators = 10 max_depth= 100 min leaf samples= 2 has score = -261.60617541\n",
      "n_estimators = 10 max_depth= 100 min leaf samples= 3 has score = -249.674110104\n",
      "n_estimators = 10 max_depth= 100 min leaf samples= 4 has score = -255.981059843\n",
      "n_estimators = 10 max_depth= 100 min leaf samples= 5 has score = -262.201330385\n",
      "n_estimators = 10 max_depth= 100 min leaf samples= 10 has score = -279.833016789\n",
      "n_estimators = 10 max_depth= 100 min leaf samples= 20 has score = -310.888598541\n",
      "n_estimators = 10 max_depth= 100 min leaf samples= 50 has score = -342.853380028\n",
      "n_estimators = 10 max_depth= 100 min leaf samples= 100 has score = -363.029257248\n",
      "n_estimators = 100 max_depth= 1 min leaf samples= 1 has score = -370.60727471\n",
      "n_estimators = 100 max_depth= 1 min leaf samples= 2 has score = -369.901307169\n",
      "n_estimators = 100 max_depth= 1 min leaf samples= 3 has score = -370.02594307\n",
      "n_estimators = 100 max_depth= 1 min leaf samples= 4 has score = -371.456548275\n",
      "n_estimators = 100 max_depth= 1 min leaf samples= 5 has score = -371.674509189\n",
      "n_estimators = 100 max_depth= 1 min leaf samples= 10 has score = -369.692183513\n",
      "n_estimators = 100 max_depth= 1 min leaf samples= 20 has score = -370.2591259\n",
      "n_estimators = 100 max_depth= 1 min leaf samples= 50 has score = -368.979372407\n",
      "n_estimators = 100 max_depth= 1 min leaf samples= 100 has score = -368.63616614\n",
      "n_estimators = 100 max_depth= 3 min leaf samples= 1 has score = -300.661072626\n",
      "n_estimators = 100 max_depth= 3 min leaf samples= 2 has score = -300.447239373\n",
      "n_estimators = 100 max_depth= 3 min leaf samples= 3 has score = -300.114030217\n",
      "n_estimators = 100 max_depth= 3 min leaf samples= 4 has score = -303.18041454\n",
      "n_estimators = 100 max_depth= 3 min leaf samples= 5 has score = -301.772553246\n",
      "n_estimators = 100 max_depth= 3 min leaf samples= 10 has score = -307.68933073\n",
      "n_estimators = 100 max_depth= 3 min leaf samples= 20 has score = -321.067316955\n",
      "n_estimators = 100 max_depth= 3 min leaf samples= 50 has score = -341.73593196\n",
      "n_estimators = 100 max_depth= 3 min leaf samples= 100 has score = -361.488201305\n",
      "n_estimators = 100 max_depth= 5 min leaf samples= 1 has score = -273.339032497\n",
      "n_estimators = 100 max_depth= 5 min leaf samples= 2 has score = -273.942726613\n",
      "n_estimators = 100 max_depth= 5 min leaf samples= 3 has score = -273.560398847\n",
      "n_estimators = 100 max_depth= 5 min leaf samples= 4 has score = -277.168375602\n",
      "n_estimators = 100 max_depth= 5 min leaf samples= 5 has score = -277.339310047\n",
      "n_estimators = 100 max_depth= 5 min leaf samples= 10 has score = -285.755835878\n",
      "n_estimators = 100 max_depth= 5 min leaf samples= 20 has score = -311.070662529\n",
      "n_estimators = 100 max_depth= 5 min leaf samples= 50 has score = -343.22312536\n",
      "n_estimators = 100 max_depth= 5 min leaf samples= 100 has score = -362.346004713\n",
      "n_estimators = 100 max_depth= 10 min leaf samples= 1 has score = -230.462250264\n",
      "n_estimators = 100 max_depth= 10 min leaf samples= 2 has score = -237.137602558\n",
      "n_estimators = 100 max_depth= 10 min leaf samples= 3 has score = -240.831100166\n",
      "n_estimators = 100 max_depth= 10 min leaf samples= 4 has score = -241.928898978\n",
      "n_estimators = 100 max_depth= 10 min leaf samples= 5 has score = -247.811664623\n",
      "n_estimators = 100 max_depth= 10 min leaf samples= 10 has score = -270.647001934\n",
      "n_estimators = 100 max_depth= 10 min leaf samples= 20 has score = -305.65991779\n",
      "n_estimators = 100 max_depth= 10 min leaf samples= 50 has score = -341.499921621\n",
      "n_estimators = 100 max_depth= 10 min leaf samples= 100 has score = -361.740281786\n",
      "n_estimators = 100 max_depth= 20 min leaf samples= 1 has score = -227.300880448\n",
      "n_estimators = 100 max_depth= 20 min leaf samples= 2 has score = -230.397731217\n",
      "n_estimators = 100 max_depth= 20 min leaf samples= 3 has score = -238.574134993\n",
      "n_estimators = 100 max_depth= 20 min leaf samples= 4 has score = -242.090272268\n",
      "n_estimators = 100 max_depth= 20 min leaf samples= 5 has score = -246.4808483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 100 max_depth= 20 min leaf samples= 10 has score = -271.836116313\n",
      "n_estimators = 100 max_depth= 20 min leaf samples= 20 has score = -306.357778716\n",
      "n_estimators = 100 max_depth= 20 min leaf samples= 50 has score = -340.619989449\n",
      "n_estimators = 100 max_depth= 20 min leaf samples= 100 has score = -361.508517393\n",
      "n_estimators = 100 max_depth= 50 min leaf samples= 1 has score = -225.665861694\n",
      "n_estimators = 100 max_depth= 50 min leaf samples= 2 has score = -229.055745558\n",
      "n_estimators = 100 max_depth= 50 min leaf samples= 3 has score = -230.516753014\n",
      "n_estimators = 100 max_depth= 50 min leaf samples= 4 has score = -242.005673726\n",
      "n_estimators = 100 max_depth= 50 min leaf samples= 5 has score = -249.881880232\n",
      "n_estimators = 100 max_depth= 50 min leaf samples= 10 has score = -272.393593275\n",
      "n_estimators = 100 max_depth= 50 min leaf samples= 20 has score = -308.83830967\n",
      "n_estimators = 100 max_depth= 50 min leaf samples= 50 has score = -342.339775492\n",
      "n_estimators = 100 max_depth= 50 min leaf samples= 100 has score = -361.940992558\n",
      "n_estimators = 100 max_depth= 100 min leaf samples= 1 has score = -229.762848465\n",
      "n_estimators = 100 max_depth= 100 min leaf samples= 2 has score = -228.62094436\n",
      "n_estimators = 100 max_depth= 100 min leaf samples= 3 has score = -233.789853428\n",
      "n_estimators = 100 max_depth= 100 min leaf samples= 4 has score = -247.545533176\n",
      "n_estimators = 100 max_depth= 100 min leaf samples= 5 has score = -247.669247252\n",
      "n_estimators = 100 max_depth= 100 min leaf samples= 10 has score = -269.078897045\n",
      "n_estimators = 100 max_depth= 100 min leaf samples= 20 has score = -307.750643649\n",
      "n_estimators = 100 max_depth= 100 min leaf samples= 50 has score = -341.227825255\n",
      "n_estimators = 100 max_depth= 100 min leaf samples= 100 has score = -361.803628866\n",
      "n_estimators = 500 max_depth= 1 min leaf samples= 1 has score = -369.530903198\n",
      "n_estimators = 500 max_depth= 1 min leaf samples= 2 has score = -369.322743194\n",
      "n_estimators = 500 max_depth= 1 min leaf samples= 3 has score = -370.093304284\n",
      "n_estimators = 500 max_depth= 1 min leaf samples= 4 has score = -370.086208089\n",
      "n_estimators = 500 max_depth= 1 min leaf samples= 5 has score = -369.84900954\n",
      "n_estimators = 500 max_depth= 1 min leaf samples= 10 has score = -370.389040227\n",
      "n_estimators = 500 max_depth= 1 min leaf samples= 20 has score = -370.211308317\n",
      "n_estimators = 500 max_depth= 1 min leaf samples= 50 has score = -369.406420478\n",
      "n_estimators = 500 max_depth= 1 min leaf samples= 100 has score = -370.078096258\n",
      "n_estimators = 500 max_depth= 3 min leaf samples= 1 has score = -300.489554858\n",
      "n_estimators = 500 max_depth= 3 min leaf samples= 2 has score = -300.532560499\n",
      "n_estimators = 500 max_depth= 3 min leaf samples= 3 has score = -301.238434028\n",
      "n_estimators = 500 max_depth= 3 min leaf samples= 4 has score = -301.07944263\n",
      "n_estimators = 500 max_depth= 3 min leaf samples= 5 has score = -301.920027145\n",
      "n_estimators = 500 max_depth= 3 min leaf samples= 10 has score = -306.946008681\n",
      "n_estimators = 500 max_depth= 3 min leaf samples= 20 has score = -320.803615627\n",
      "n_estimators = 500 max_depth= 3 min leaf samples= 50 has score = -341.27988094\n",
      "n_estimators = 500 max_depth= 3 min leaf samples= 100 has score = -360.800317284\n",
      "n_estimators = 500 max_depth= 5 min leaf samples= 1 has score = -271.348443692\n",
      "n_estimators = 500 max_depth= 5 min leaf samples= 2 has score = -272.329284632\n",
      "n_estimators = 500 max_depth= 5 min leaf samples= 3 has score = -274.300277791\n",
      "n_estimators = 500 max_depth= 5 min leaf samples= 4 has score = -274.52821343\n",
      "n_estimators = 500 max_depth= 5 min leaf samples= 5 has score = -275.70305162\n",
      "n_estimators = 500 max_depth= 5 min leaf samples= 10 has score = -284.523694224\n",
      "n_estimators = 500 max_depth= 5 min leaf samples= 20 has score = -307.753451208\n",
      "n_estimators = 500 max_depth= 5 min leaf samples= 50 has score = -342.207359765\n",
      "n_estimators = 500 max_depth= 5 min leaf samples= 100 has score = -361.024688719\n",
      "n_estimators = 500 max_depth= 10 min leaf samples= 1 has score = -227.747032162\n",
      "n_estimators = 500 max_depth= 10 min leaf samples= 2 has score = -232.209339317\n",
      "n_estimators = 500 max_depth= 10 min leaf samples= 3 has score = -237.192602124\n",
      "n_estimators = 500 max_depth= 10 min leaf samples= 4 has score = -242.745321954\n",
      "n_estimators = 500 max_depth= 10 min leaf samples= 5 has score = -248.989201401\n",
      "n_estimators = 500 max_depth= 10 min leaf samples= 10 has score = -271.31818045\n",
      "n_estimators = 500 max_depth= 10 min leaf samples= 20 has score = -309.107701806\n",
      "n_estimators = 500 max_depth= 10 min leaf samples= 50 has score = -341.5740035\n",
      "n_estimators = 500 max_depth= 10 min leaf samples= 100 has score = -360.02980582\n",
      "n_estimators = 500 max_depth= 20 min leaf samples= 1 has score = -219.813957639\n",
      "n_estimators = 500 max_depth= 20 min leaf samples= 2 has score = -226.306239718\n",
      "n_estimators = 500 max_depth= 20 min leaf samples= 3 has score = -232.944604332\n",
      "n_estimators = 500 max_depth= 20 min leaf samples= 4 has score = -241.642595594\n",
      "n_estimators = 500 max_depth= 20 min leaf samples= 5 has score = -248.498685141\n",
      "n_estimators = 500 max_depth= 20 min leaf samples= 10 has score = -270.612306009\n",
      "n_estimators = 500 max_depth= 20 min leaf samples= 20 has score = -307.853694913\n",
      "n_estimators = 500 max_depth= 20 min leaf samples= 50 has score = -341.91610735\n",
      "n_estimators = 500 max_depth= 20 min leaf samples= 100 has score = -361.340542133\n",
      "n_estimators = 500 max_depth= 50 min leaf samples= 1 has score = -224.502874729\n",
      "n_estimators = 500 max_depth= 50 min leaf samples= 2 has score = -227.25796854\n",
      "n_estimators = 500 max_depth= 50 min leaf samples= 3 has score = -235.006381573\n",
      "n_estimators = 500 max_depth= 50 min leaf samples= 4 has score = -240.554768959\n",
      "n_estimators = 500 max_depth= 50 min leaf samples= 5 has score = -249.100988724\n",
      "n_estimators = 500 max_depth= 50 min leaf samples= 10 has score = -271.534606649\n",
      "n_estimators = 500 max_depth= 50 min leaf samples= 20 has score = -306.630796812\n",
      "n_estimators = 500 max_depth= 50 min leaf samples= 50 has score = -342.312007785\n",
      "n_estimators = 500 max_depth= 50 min leaf samples= 100 has score = -361.623537272\n",
      "n_estimators = 500 max_depth= 100 min leaf samples= 1 has score = -223.488441182\n",
      "n_estimators = 500 max_depth= 100 min leaf samples= 2 has score = -224.779296972\n",
      "n_estimators = 500 max_depth= 100 min leaf samples= 3 has score = -233.390698543\n",
      "n_estimators = 500 max_depth= 100 min leaf samples= 4 has score = -240.896717192\n",
      "n_estimators = 500 max_depth= 100 min leaf samples= 5 has score = -249.021403812\n",
      "n_estimators = 500 max_depth= 100 min leaf samples= 10 has score = -270.731118845\n",
      "n_estimators = 500 max_depth= 100 min leaf samples= 20 has score = -308.157274906\n",
      "n_estimators = 500 max_depth= 100 min leaf samples= 50 has score = -341.78171733\n",
      "n_estimators = 500 max_depth= 100 min leaf samples= 100 has score = -361.055797584\n",
      "n_estimators = 1000 max_depth= 1 min leaf samples= 1 has score = -370.502868843\n",
      "n_estimators = 1000 max_depth= 1 min leaf samples= 2 has score = -370.44438636\n",
      "n_estimators = 1000 max_depth= 1 min leaf samples= 3 has score = -369.640043055\n",
      "n_estimators = 1000 max_depth= 1 min leaf samples= 4 has score = -369.929920389\n",
      "n_estimators = 1000 max_depth= 1 min leaf samples= 5 has score = -370.011141188\n",
      "n_estimators = 1000 max_depth= 1 min leaf samples= 10 has score = -369.719744391\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f942b4bd11ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"n_estimators =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"max_depth=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"min leaf samples=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"has score =\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[0;32m--> 314\u001b[0;31m                                             random_state=random_state)\n\u001b[0m\u001b[1;32m    315\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/base.pyc\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0m_set_random_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/base.pyc\u001b[0m in \u001b[0;36m_set_random_states\u001b[0;34m(estimator, random_state)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mto_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mto_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;31m# Simple optimisation to gain speed (inspect is slow)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mvalid_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[1;32m    234\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0;31m# We need deprecation warnings to always be on in order to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;31m# catch deprecated param values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;31m# to represent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__self__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;31m# Unbound method: the first parameter becomes positional-only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36msignature\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36mfrom_function\u001b[0;34m(cls, func)\u001b[0m\n\u001b[1;32m    581\u001b[0m         return cls(parameters,\n\u001b[1;32m    582\u001b[0m                    \u001b[0mreturn_annotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'return'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                    __validate_parameters__=False)\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/site-packages/sklearn/externals/funcsigs.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parameters, return_annotation, __validate_parameters__)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 params = OrderedDict(((param.name, param)\n\u001b[0;32m--> 507\u001b[0;31m                                                 for param in parameters))\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/collections.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_setitem\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/_abcoll.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lara/anaconda2/lib/python2.7/collections.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value, dict_setitem)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__root\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mlast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict_setitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimators = [10, 100, 500, 1000]\n",
    "depth = [1,3,5,10,20,50,100]\n",
    "leaves = [1, 2, 3, 4, 5, 10, 20, 50, 100]\n",
    "\n",
    "for e in estimators:\n",
    "    for d in depth:\n",
    "         for leaf in leaves:\n",
    "            results =[]\n",
    "            kfold = model_selection.KFold(n_splits=10, shuffle = True, random_state=11)\n",
    "            results = model_selection.cross_val_score(RandomForestRegressor(n_estimators = e, max_depth = d, min_samples_leaf = leaf), X, Y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "            score = results.mean()\n",
    "            print \"n_estimators =\", e, \"max_depth=\", d, \"min leaf samples=\", leaf, \"has score =\",score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
