{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing as pp\n",
    "%pylab inline\n",
    "\n",
    "cause = pd.read_csv('/home/lara/Documents/Repository/Capstone-1_WorldBank_GenderData/causes.csv')\n",
    "effect = pd.read_csv('/home/lara/Documents/Repository/Capstone-1_WorldBank_GenderData/effects.csv')\n",
    "\n",
    "\n",
    "# Supervised Learning Modules\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping through various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('SGDR', SGDRegressor()))\n",
    "models.append(('GaussianPR', GaussianProcessRegressor()))\n",
    "models.append(('KNN', KNeighborsRegressor()))\n",
    "models.append(('DTree', DecisionTreeRegressor()))\n",
    "models.append(('GradientBR', GradientBoostingRegressor()))\n",
    "models.append(('SVR', SVR()))\n",
    "models.append(('RF', RandomForestRegressor(n_jobs = -1, n_estimators = 500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = cause.pop('bc')\n",
    "X = cause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    # boxplot algorithm comparison\\n    fig = pyplot.figure()\\n    fig.suptitle(title)\\n    ax = fig.add_subplot(111)\\n    pyplot.boxplot(results)\\n    ax.set_xticklabels(names)\\n    pyplot.ylim(0,1)\\n    pyplot.show()\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a function to evaluate each model\n",
    "def run_models(x,y):\n",
    "    results = []\n",
    "    names = []\n",
    "\n",
    "    for name, model in models:\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle = True, random_state=11)\n",
    "        cv_results = model_selection.cross_val_score(model, x, y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "'''\n",
    "    # boxplot algorithm comparison\n",
    "    fig = pyplot.figure()\n",
    "    fig.suptitle(title)\n",
    "    ax = fig.add_subplot(111)\n",
    "    pyplot.boxplot(results)\n",
    "    ax.set_xticklabels(names)\n",
    "    pyplot.ylim(0,1)\n",
    "    pyplot.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDR: -71155615444173776472866578451398656.000000 (100488112409887734351412239781593088.000000)\n",
      "GaussianPR: -2880.365325 (360.577292)\n",
      "KNN: -380.370038 (67.390897)\n",
      "DTree: -419.900412 (109.487188)\n",
      "GradientBR: -214.404800 (49.169755)\n",
      "SVR: -542.577257 (62.328021)\n",
      "RF: -221.542367 (51.034570)\n"
     ]
    }
   ],
   "source": [
    "run_models(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tuning the SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.001  and Epsilon = 0.0001 has score = -543.261142024\n",
      "C= 0.001  and Epsilon = 0.001 has score = -543.258900696\n",
      "C= 0.001  and Epsilon = 0.1 has score = -543.167182494\n",
      "C= 0.001  and Epsilon = 1 has score = -543.123666591\n",
      "C= 0.001  and Epsilon = 10 has score = -535.061387644\n",
      "C= 0.1  and Epsilon = 0.0001 has score = -543.042260735\n",
      "C= 0.1  and Epsilon = 0.001 has score = -543.042846983\n",
      "C= 0.1  and Epsilon = 0.1 has score = -543.249956514\n",
      "C= 0.1  and Epsilon = 1 has score = -543.009580546\n",
      "C= 0.1  and Epsilon = 10 has score = -535.042783806\n",
      "C= 1  and Epsilon = 0.0001 has score = -542.633125612\n",
      "C= 1  and Epsilon = 0.001 has score = -542.632876452\n",
      "C= 1  and Epsilon = 0.1 has score = -542.577256648\n",
      "C= 1  and Epsilon = 1 has score = -541.769006908\n",
      "C= 1  and Epsilon = 10 has score = -533.539445992\n",
      "C= 10  and Epsilon = 0.0001 has score = -532.291140532\n",
      "C= 10  and Epsilon = 0.001 has score = -532.290232137\n",
      "C= 10  and Epsilon = 0.1 has score = -532.188390945\n",
      "C= 10  and Epsilon = 1 has score = -531.287471765\n",
      "C= 10  and Epsilon = 10 has score = -527.051461004\n",
      "C= 100  and Epsilon = 0.0001 has score = -516.805505796\n",
      "C= 100  and Epsilon = 0.001 has score = -516.805711511\n",
      "C= 100  and Epsilon = 0.1 has score = -516.828222824\n",
      "C= 100  and Epsilon = 1 has score = -517.041855323\n",
      "C= 100  and Epsilon = 10 has score = -519.887351689\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.001, 0.1, 1, 10, 100]\n",
    "Es = [0.0001, 0.001, 0.1, 1, 10]\n",
    "\n",
    "for i in Cs:\n",
    "    for e in Es:\n",
    "        results =[]\n",
    "        kfold = model_selection.KFold(n_splits=10, shuffle = True, random_state=11)\n",
    "        results = model_selection.cross_val_score(SVR(C=i, epsilon = e), X, Y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "        score = results.mean()\n",
    "        print \"C=\", i, \" and Epsilon =\", e, \"has score =\",score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-825be335824b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-825be335824b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    loss_opt= [‘ls’, ‘lad’, ‘huber’, ‘quantile’]\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "loss_opt= [‘ls’, ‘lad’, ‘huber’, ‘quantile’]\n",
    "estimators = [10, 100, 500, 1000]\n",
    "depth = [1,3,5,10,20,50,100]\n",
    "leaves = [1, 2, 3, 4, 5, 10, 20, 50, 100]\n",
    "\n",
    "for l in loss_opt:\n",
    "    for e in estimators:\n",
    "        for d in depth:\n",
    "            for leaf in leaves:\n",
    "                results =[]\n",
    "                kfold = model_selection.KFold(n_splits=10, shuffle = True, random_state=11)\n",
    "                results = model_selection.cross_val_score(GradientBoostingRegressor(loss=loss, n_estimators = e, max_depth = d, min_samples_leaf = leaf), X, Y, cv=kfold, scoring='neg_mean_squared_error')\n",
    "                score = results.mean()\n",
    "                print \"Loss Function:\", l, \"n_estimators =\", e, \"max_depth=\", d, \"has score =\",score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
